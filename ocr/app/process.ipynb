{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 14:44:49.055659: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from paddleocr import PaddleOCR\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2024/04/30 14:44:56] ppocr DEBUG: Namespace(help='==SUPPRESS==', use_gpu=False, use_xpu=False, use_npu=False, ir_optim=True, use_tensorrt=False, min_subgraph_size=15, precision='fp32', gpu_mem=500, gpu_id=0, image_dir=None, page_num=0, det_algorithm='DB', det_model_dir='/home/abdo/.paddleocr/whl/det/ch/ch_PP-OCRv4_det_infer', det_limit_side_len=960, det_limit_type='max', det_box_type='quad', det_db_thresh=0.3, det_db_box_thresh=0.6, det_db_unclip_ratio=1.5, max_batch_size=10, use_dilation=False, det_db_score_mode='fast', det_east_score_thresh=0.8, det_east_cover_thresh=0.1, det_east_nms_thresh=0.2, det_sast_score_thresh=0.5, det_sast_nms_thresh=0.2, det_pse_thresh=0, det_pse_box_thresh=0.85, det_pse_min_area=16, det_pse_scale=1, scales=[8, 16, 32], alpha=1.0, beta=1.0, fourier_degree=5, rec_algorithm='SVTR_LCNet', rec_model_dir='/home/abdo/.paddleocr/whl/rec/ch/ch_PP-OCRv4_rec_infer', rec_image_inverse=True, rec_image_shape='3, 48, 320', rec_batch_num=6, max_text_length=25, rec_char_dict_path='/home/abdo/microservices/ocr/ocrenv/lib/python3.9/site-packages/paddleocr/ppocr/utils/ppocr_keys_v1.txt', use_space_char=True, vis_font_path='./doc/fonts/simfang.ttf', drop_score=0.5, e2e_algorithm='PGNet', e2e_model_dir=None, e2e_limit_side_len=768, e2e_limit_type='max', e2e_pgnet_score_thresh=0.5, e2e_char_dict_path='./ppocr/utils/ic15_dict.txt', e2e_pgnet_valid_set='totaltext', e2e_pgnet_mode='fast', use_angle_cls=True, cls_model_dir='/home/abdo/.paddleocr/whl/cls/ch_ppocr_mobile_v2.0_cls_infer', cls_image_shape='3, 48, 192', label_list=['0', '180'], cls_batch_num=6, cls_thresh=0.9, enable_mkldnn=False, cpu_threads=10, use_pdserving=False, warmup=False, sr_model_dir=None, sr_image_shape='3, 32, 128', sr_batch_num=1, draw_img_save_dir='./inference_results', save_crop_res=False, crop_res_save_dir='./output', use_mp=False, total_process_num=1, process_id=0, benchmark=False, save_log_path='./log_output/', show_log=True, use_onnx=False, output='./output', table_max_len=488, table_algorithm='TableAttn', table_model_dir=None, merge_no_span_structure=True, table_char_dict_path=None, layout_model_dir=None, layout_dict_path=None, layout_score_threshold=0.5, layout_nms_threshold=0.5, kie_algorithm='LayoutXLM', ser_model_dir=None, re_model_dir=None, use_visual_backbone=True, ser_dict_path='../train_data/XFUND/class_list_xfun.txt', ocr_order_method=None, mode='structure', image_orientation=False, layout=True, table=True, ocr=True, recovery=False, use_pdf2docx_api=False, invert=False, binarize=False, alphacolor=(255, 255, 255), lang='ch', det=True, rec=True, type='ocr', ocr_version='PP-OCRv4', structure_version='PP-StructureV2')\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "ocr = PaddleOCR(use_angle_cls=True, lang=\"ch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(img):\n",
    "    result = ocr.ocr(img, cls=False)\n",
    "    return result[0]\n",
    "\n",
    "\n",
    "def get_raw_text_from_pages(pages):\n",
    "    raw_text = {}\n",
    "    results = []\n",
    "    for page_num, page in enumerate(pages, start=1):\n",
    "        result = extract_text(page)\n",
    "        results.append((page, result))\n",
    "        raw_text[page_num] = \"\\n\".join([line[1][0] for line in result])\n",
    "    return results, raw_text\n",
    "\n",
    "def intersection(box_1, box_2):\n",
    "    return [box_2[0], box_1[1], box_2[2], box_1[3]]\n",
    "\n",
    "\n",
    "def iou(box_1, box_2):\n",
    "    x_1 = max(box_1[0], box_2[0])\n",
    "    y_1 = max(box_1[1], box_2[1])\n",
    "    x_2 = min(box_1[2], box_2[2])\n",
    "    y_2 = min(box_1[3], box_2[3])\n",
    "\n",
    "    inter = abs(max((x_2 - x_1, 0)) * max((y_2 - y_1), 0))\n",
    "    if inter == 0:\n",
    "        return 0\n",
    "\n",
    "    box_1_area = abs((box_1[2] - box_1[0]) * (box_1[3] - box_1[1]))\n",
    "    box_2_area = abs((box_2[2] - box_2[0]) * (box_2[3] - box_2[1]))\n",
    "\n",
    "    return inter / float(box_1_area + box_2_area - inter)\n",
    "\n",
    "\n",
    "def get_data(img, output):\n",
    "    image_height = img.shape[0]\n",
    "    image_width = img.shape[1]\n",
    "\n",
    "    boxes = [line[0] for line in output]\n",
    "    texts = [line[1][0] for line in output]\n",
    "    probabilities = [line[1][1] for line in output]\n",
    "\n",
    "    horiz_boxes = []\n",
    "    vert_boxes = []\n",
    "\n",
    "    for box in boxes:\n",
    "        x_h, x_v = 0, int(box[0][0])\n",
    "        y_h, y_v = int(box[0][1]), 0\n",
    "        width_h, width_v = image_width, int(box[2][0] - box[0][0])\n",
    "        height_h, height_v = int(box[2][1] - box[0][1]), image_height\n",
    "\n",
    "        horiz_boxes.append([x_h, y_h, x_h + width_h, y_h + height_h])\n",
    "        vert_boxes.append([x_v, y_v, x_v + width_v, y_v + height_v])\n",
    "\n",
    "    horiz_out = tf.image.non_max_suppression(\n",
    "        horiz_boxes,\n",
    "        probabilities,\n",
    "        max_output_size=1000,\n",
    "        iou_threshold=0.1,\n",
    "        score_threshold=float(\"-inf\"),\n",
    "        name=None,\n",
    "    )\n",
    "\n",
    "    horiz_lines = np.sort(np.array(horiz_out))\n",
    "\n",
    "    vert_out = tf.image.non_max_suppression(\n",
    "        vert_boxes,\n",
    "        probabilities,\n",
    "        max_output_size=1000,\n",
    "        iou_threshold=0.1,\n",
    "        score_threshold=float(\"-inf\"),\n",
    "        name=None,\n",
    "    )\n",
    "    vert_lines = np.sort(np.array(vert_out))\n",
    "\n",
    "    out_array = [\"\" for _ in range(len(horiz_lines))]\n",
    "\n",
    "    unordered_boxes = []\n",
    "\n",
    "    for i in vert_lines:\n",
    "        unordered_boxes.append(vert_boxes[i][0])\n",
    "\n",
    "    ordered_boxes = np.argsort(unordered_boxes)\n",
    "\n",
    "    for i in range(len(horiz_lines)):\n",
    "        for j in range(len(vert_lines)):\n",
    "            resultant = intersection(\n",
    "                horiz_boxes[horiz_lines[i]], vert_boxes[vert_lines[ordered_boxes[j]]]\n",
    "            )\n",
    "\n",
    "            for b in range(len(boxes)):\n",
    "                the_box = [\n",
    "                    boxes[b][0][0],\n",
    "                    boxes[b][0][1],\n",
    "                    boxes[b][2][0],\n",
    "                    boxes[b][2][1],\n",
    "                ]\n",
    "                if iou(resultant, the_box) > 0.1:\n",
    "                    out_array[i] += f\" {texts[b]}\"\n",
    "\n",
    "    out_array = np.array(out_array)\n",
    "    return out_array\n",
    "\n",
    "\n",
    "def get_processed_text_from_pages(results):\n",
    "    processed_text = {}\n",
    "    for page_num, (img, result) in enumerate(results, start=1):\n",
    "        output = get_data(img, result)\n",
    "        processed_text[page_num] = \"\\n\".join(text for text in output)\n",
    "\n",
    "    return processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"27786.jpg\"\n",
    "img = cv2.imread(filename)\n",
    "pages = [img]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pdf_pages = convert_from_path(filename, 500)\n",
    "# pages = [np.asarray(page) for page in pdf_pages]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results, raw_text = get_raw_text_from_pages(pages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = get_processed_text_from_pages(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ocrenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
